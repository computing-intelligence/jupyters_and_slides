{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        self.gradients = {}\n",
    "        # keys are the inputs to this node, and their\n",
    "        # values are the partials of this node with \n",
    "        # respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        '''\n",
    "        Forward propagation. \n",
    "        Compute the output value vased on 'inbound_nodes' and store the \n",
    "        result in self.value\n",
    "        '''\n",
    "\n",
    "        raise NotImplemented\n",
    "    \n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        raise NotImplemented\n",
    "        \n",
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        An Input node has no inbound nodes.\n",
    "        So no need to pass anything to the Node instantiator.\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        '''\n",
    "        Only input node is the node where the value may be passed\n",
    "        as an argument to forward().\n",
    "        All other node implementations should get the value of the \n",
    "        previous node from self.inbound_nodes\n",
    "        \n",
    "        Example: \n",
    "        val0: self.inbound_nodes[0].value\n",
    "        '''\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            ## It's is input node, when need to forward, this node initiate self's value.\n",
    "\n",
    "        # Input subclass just holds a value, such as a data feature or a model parameter(weight/bias)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1\n",
    "            \n",
    "        \n",
    "        # input N --> N1, N2\n",
    "        # \\partial L / \\partial N \n",
    "        # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N\n",
    "\n",
    "\n",
    "class Add(Node):\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))\n",
    "        ## when execute forward, this node caculate value as defined.\n",
    "\n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        \n",
    "    def backward(self):\n",
    "\n",
    "        # initial a partial for each of the inbound_nodes.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            # Get the partial of the cost w.r.t this node.\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)\n",
    "\n",
    "        # WX + B / W ==> X\n",
    "        # WX + B / X ==> W\n",
    "\n",
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^-x)\n",
    "        # y' = 1 / (1 + e^-x) (1 - 1 / (1 + e^-x))\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]  # Get the partial of the cost with respect to this node.\n",
    "\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to keep all the dimension same!.\n",
    "\n",
    "\n",
    "\n",
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "\n",
    "def forward_and_backward(outputnode, graph):\n",
    "    # execute all the forward method of sorted_nodes.\n",
    "\n",
    "    ## In practice, it's common to feed in mutiple data example in each forward pass rather than just 1. Because the examples can be processed in parallel. The number of examples is called batch size.\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        ## each node execute forward, get self.value based on the topological sort result.\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "    #return outputnode.value\n",
    "\n",
    "###   v -->  a -->  C\n",
    "##    b --> C\n",
    "##    b --> v -- a --> C\n",
    "##    v --> v ---> a -- > C\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    # there are so many other update / optimization methods\n",
    "    # such as Adam, Mom, \n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n",
      "Epoch: 1, Loss: 210.832\n",
      "Epoch: 101, Loss: 8.064\n",
      "Epoch: 201, Loss: 5.622\n",
      "Epoch: 301, Loss: 4.126\n",
      "Epoch: 401, Loss: 4.380\n",
      "Epoch: 501, Loss: 4.099\n",
      "Epoch: 601, Loss: 4.445\n",
      "Epoch: 701, Loss: 3.716\n",
      "Epoch: 801, Loss: 3.768\n",
      "Epoch: 901, Loss: 2.964\n",
      "Epoch: 1001, Loss: 3.391\n",
      "Epoch: 1101, Loss: 3.116\n",
      "Epoch: 1201, Loss: 3.693\n",
      "Epoch: 1301, Loss: 3.133\n",
      "Epoch: 1401, Loss: 3.540\n",
      "Epoch: 1501, Loss: 3.155\n",
      "Epoch: 1601, Loss: 3.801\n",
      "Epoch: 1701, Loss: 3.183\n",
      "Epoch: 1801, Loss: 3.478\n",
      "Epoch: 1901, Loss: 3.554\n",
      "Epoch: 2001, Loss: 3.158\n",
      "Epoch: 2101, Loss: 3.114\n",
      "Epoch: 2201, Loss: 3.314\n",
      "Epoch: 2301, Loss: 3.374\n",
      "Epoch: 2401, Loss: 2.714\n",
      "Epoch: 2501, Loss: 3.229\n",
      "Epoch: 2601, Loss: 2.775\n",
      "Epoch: 2701, Loss: 3.312\n",
      "Epoch: 2801, Loss: 3.002\n",
      "Epoch: 2901, Loss: 3.187\n",
      "Epoch: 3001, Loss: 2.935\n",
      "Epoch: 3101, Loss: 3.097\n",
      "Epoch: 3201, Loss: 3.020\n",
      "Epoch: 3301, Loss: 2.978\n",
      "Epoch: 3401, Loss: 2.732\n",
      "Epoch: 3501, Loss: 3.067\n",
      "Epoch: 3601, Loss: 2.493\n",
      "Epoch: 3701, Loss: 2.988\n",
      "Epoch: 3801, Loss: 2.607\n",
      "Epoch: 3901, Loss: 3.166\n",
      "Epoch: 4001, Loss: 2.962\n",
      "Epoch: 4101, Loss: 3.368\n",
      "Epoch: 4201, Loss: 3.338\n",
      "Epoch: 4301, Loss: 2.816\n",
      "Epoch: 4401, Loss: 2.525\n",
      "Epoch: 4501, Loss: 2.897\n",
      "Epoch: 4601, Loss: 2.749\n",
      "Epoch: 4701, Loss: 2.973\n",
      "Epoch: 4801, Loss: 3.296\n",
      "Epoch: 4901, Loss: 2.804\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check out the new network architecture and dataset!\n",
    "Notice that the weights and biases are\n",
    "generated randomly.\n",
    "No need to change anything, but feel free to tweak\n",
    "to test your network, play around with the epochs, batch size, etc!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "#from miniflow import *\n",
    "\n",
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 5000\n",
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))\n",
    "\n",
    "# Step 4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2\n",
    "    \n",
    "        sgd_update(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a32ee8d68>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.06675992],\n",
       "       [  8.23298865],\n",
       "       [  8.80431613],\n",
       "       [-13.36338757],\n",
       "       [  9.65316777],\n",
       "       [  5.96190503],\n",
       "       [ 10.99998584],\n",
       "       [  3.48275087],\n",
       "       [  3.78735499],\n",
       "       [ 12.03614078]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='sigmoid', input_dim=13))\n",
    "model.add(Dense(units=30, activation='sigmoid', input_dim=64))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "506/506 [==============================] - 0s 482us/step - loss: 143.4432 - mean_squared_error: 143.4432\n",
      "Epoch 2/5000\n",
      "506/506 [==============================] - 0s 42us/step - loss: 82.3686 - mean_squared_error: 82.3686\n",
      "Epoch 3/5000\n",
      "506/506 [==============================] - 0s 42us/step - loss: 77.3528 - mean_squared_error: 77.3528\n",
      "Epoch 4/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 76.8472 - mean_squared_error: 76.8472\n",
      "Epoch 5/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 75.8336 - mean_squared_error: 75.8336\n",
      "Epoch 6/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 78.7476 - mean_squared_error: 78.7476\n",
      "Epoch 7/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 79.6914 - mean_squared_error: 79.6914\n",
      "Epoch 8/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 78.6502 - mean_squared_error: 78.6502\n",
      "Epoch 9/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 74.4281 - mean_squared_error: 74.4281\n",
      "Epoch 10/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 74.3106 - mean_squared_error: 74.3106\n",
      "Epoch 11/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 74.9850 - mean_squared_error: 74.9850\n",
      "Epoch 12/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 74.8295 - mean_squared_error: 74.8295\n",
      "Epoch 13/5000\n",
      "506/506 [==============================] - 0s 34us/step - loss: 76.8475 - mean_squared_error: 76.8475\n",
      "Epoch 14/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 85.1263 - mean_squared_error: 85.1263\n",
      "Epoch 15/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 88.4637 - mean_squared_error: 88.4637\n",
      "Epoch 16/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 89.6845 - mean_squared_error: 89.6845\n",
      "Epoch 17/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.8725 - mean_squared_error: 84.8725\n",
      "Epoch 18/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 85.7164 - mean_squared_error: 85.7164\n",
      "Epoch 19/5000\n",
      "506/506 [==============================] - 0s 35us/step - loss: 84.9748 - mean_squared_error: 84.9748\n",
      "Epoch 20/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 86.1252 - mean_squared_error: 86.1252\n",
      "Epoch 21/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 87.4500 - mean_squared_error: 87.4500\n",
      "Epoch 22/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.7354 - mean_squared_error: 85.7354\n",
      "Epoch 23/5000\n",
      "506/506 [==============================] - 0s 39us/step - loss: 84.9278 - mean_squared_error: 84.9278\n",
      "Epoch 24/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 85.7913 - mean_squared_error: 85.7913\n",
      "Epoch 25/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 85.0535 - mean_squared_error: 85.0535\n",
      "Epoch 26/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 85.0658 - mean_squared_error: 85.0658\n",
      "Epoch 27/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.7904 - mean_squared_error: 85.7904\n",
      "Epoch 28/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.2221 - mean_squared_error: 85.2221\n",
      "Epoch 29/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 85.4434 - mean_squared_error: 85.4434\n",
      "Epoch 30/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.6103 - mean_squared_error: 85.6103\n",
      "Epoch 31/5000\n",
      "506/506 [==============================] - 0s 36us/step - loss: 85.4166 - mean_squared_error: 85.4166\n",
      "Epoch 32/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 84.5406 - mean_squared_error: 84.5406\n",
      "Epoch 33/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.1172 - mean_squared_error: 85.1172\n",
      "Epoch 34/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 85.6599 - mean_squared_error: 85.6599\n",
      "Epoch 35/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.1513 - mean_squared_error: 85.1513\n",
      "Epoch 36/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 84.8684 - mean_squared_error: 84.8684\n",
      "Epoch 37/5000\n",
      "506/506 [==============================] - 0s 33us/step - loss: 85.7398 - mean_squared_error: 85.7398\n",
      "Epoch 38/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.5626 - mean_squared_error: 84.5626\n",
      "Epoch 39/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 84.6975 - mean_squared_error: 84.6975\n",
      "Epoch 40/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.4825 - mean_squared_error: 84.4825\n",
      "Epoch 41/5000\n",
      "506/506 [==============================] - 0s 39us/step - loss: 84.5680 - mean_squared_error: 84.5680\n",
      "Epoch 42/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 84.9623 - mean_squared_error: 84.9623\n",
      "Epoch 43/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.3657 - mean_squared_error: 85.3657\n",
      "Epoch 44/5000\n",
      "506/506 [==============================] - 0s 42us/step - loss: 85.3019 - mean_squared_error: 85.3019\n",
      "Epoch 45/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 85.2700 - mean_squared_error: 85.2700\n",
      "Epoch 46/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 85.1239 - mean_squared_error: 85.1239\n",
      "Epoch 47/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 84.9346 - mean_squared_error: 84.9346\n",
      "Epoch 48/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.8322 - mean_squared_error: 84.8322\n",
      "Epoch 49/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 85.3293 - mean_squared_error: 85.3293\n",
      "Epoch 50/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.4013 - mean_squared_error: 85.4013\n",
      "Epoch 51/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.6436 - mean_squared_error: 85.6436\n",
      "Epoch 52/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.6256 - mean_squared_error: 85.6256\n",
      "Epoch 53/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 84.7833 - mean_squared_error: 84.7833\n",
      "Epoch 54/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.8088 - mean_squared_error: 84.8088\n",
      "Epoch 55/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 84.6359 - mean_squared_error: 84.6359\n",
      "Epoch 56/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 84.4420 - mean_squared_error: 84.4420\n",
      "Epoch 57/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.5745 - mean_squared_error: 85.5745\n",
      "Epoch 58/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.0695 - mean_squared_error: 85.0695\n",
      "Epoch 59/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.7676 - mean_squared_error: 84.7676\n",
      "Epoch 60/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.5295 - mean_squared_error: 84.5295\n",
      "Epoch 61/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.7503 - mean_squared_error: 84.7503\n",
      "Epoch 62/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 85.2943 - mean_squared_error: 85.2943\n",
      "Epoch 63/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 85.2788 - mean_squared_error: 85.2788\n",
      "Epoch 64/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.3548 - mean_squared_error: 85.3548\n",
      "Epoch 65/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 84.6432 - mean_squared_error: 84.6432\n",
      "Epoch 66/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.5094 - mean_squared_error: 84.5094\n",
      "Epoch 67/5000\n",
      "506/506 [==============================] - 0s 79us/step - loss: 84.8343 - mean_squared_error: 84.8343\n",
      "Epoch 68/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.3985 - mean_squared_error: 85.3985\n",
      "Epoch 69/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.9762 - mean_squared_error: 84.9762\n",
      "Epoch 70/5000\n",
      "506/506 [==============================] - 0s 35us/step - loss: 85.1308 - mean_squared_error: 85.1308\n",
      "Epoch 71/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 36us/step - loss: 85.1061 - mean_squared_error: 85.1061\n",
      "Epoch 72/5000\n",
      "506/506 [==============================] - 0s 42us/step - loss: 85.9251 - mean_squared_error: 85.9251\n",
      "Epoch 73/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.6596 - mean_squared_error: 85.6596\n",
      "Epoch 74/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.0436 - mean_squared_error: 85.0436\n",
      "Epoch 75/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.7368 - mean_squared_error: 84.7368\n",
      "Epoch 76/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.8656 - mean_squared_error: 84.8656\n",
      "Epoch 77/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.8080 - mean_squared_error: 84.8080\n",
      "Epoch 78/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.2302 - mean_squared_error: 85.2302\n",
      "Epoch 79/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.5889 - mean_squared_error: 85.5889\n",
      "Epoch 80/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.1431 - mean_squared_error: 85.1431\n",
      "Epoch 81/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.8358 - mean_squared_error: 85.8358\n",
      "Epoch 82/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.7320 - mean_squared_error: 85.7320\n",
      "Epoch 83/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.0127 - mean_squared_error: 85.0127\n",
      "Epoch 84/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.7259 - mean_squared_error: 85.7259\n",
      "Epoch 85/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 86.2586 - mean_squared_error: 86.2586\n",
      "Epoch 86/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.3898 - mean_squared_error: 85.3898\n",
      "Epoch 87/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.9969 - mean_squared_error: 84.9969\n",
      "Epoch 88/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.2161 - mean_squared_error: 85.2161\n",
      "Epoch 89/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.8121 - mean_squared_error: 84.8121\n",
      "Epoch 90/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.3470 - mean_squared_error: 85.3470\n",
      "Epoch 91/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 85.2808 - mean_squared_error: 85.2808\n",
      "Epoch 92/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.5244 - mean_squared_error: 85.5244\n",
      "Epoch 93/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.7538 - mean_squared_error: 85.7538\n",
      "Epoch 94/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.2039 - mean_squared_error: 85.2039\n",
      "Epoch 95/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.0566 - mean_squared_error: 85.0566\n",
      "Epoch 96/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.2410 - mean_squared_error: 85.2410\n",
      "Epoch 97/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.0608 - mean_squared_error: 85.0608\n",
      "Epoch 98/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.9028 - mean_squared_error: 85.9028\n",
      "Epoch 99/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.3375 - mean_squared_error: 85.3375\n",
      "Epoch 100/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.9887 - mean_squared_error: 84.9887\n",
      "Epoch 101/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 84.8838 - mean_squared_error: 84.8838\n",
      "Epoch 102/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.1226 - mean_squared_error: 85.1226\n",
      "Epoch 103/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.5668 - mean_squared_error: 84.5668\n",
      "Epoch 104/5000\n",
      "506/506 [==============================] - 0s 81us/step - loss: 84.4731 - mean_squared_error: 84.4731\n",
      "Epoch 105/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.9594 - mean_squared_error: 84.9594\n",
      "Epoch 106/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.6458 - mean_squared_error: 85.6458\n",
      "Epoch 107/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.5375 - mean_squared_error: 85.5375\n",
      "Epoch 108/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 84.2950 - mean_squared_error: 84.2950\n",
      "Epoch 109/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.5529 - mean_squared_error: 85.5529\n",
      "Epoch 110/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.9323 - mean_squared_error: 84.9323\n",
      "Epoch 111/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.8903 - mean_squared_error: 84.8903\n",
      "Epoch 112/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.3986 - mean_squared_error: 85.3986\n",
      "Epoch 113/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.1139 - mean_squared_error: 85.1139\n",
      "Epoch 114/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.9884 - mean_squared_error: 84.9884\n",
      "Epoch 115/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.2846 - mean_squared_error: 85.2846\n",
      "Epoch 116/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 84.8478 - mean_squared_error: 84.8478\n",
      "Epoch 117/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.7682 - mean_squared_error: 84.7682\n",
      "Epoch 118/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.6082 - mean_squared_error: 84.6082\n",
      "Epoch 119/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.3597 - mean_squared_error: 85.3597\n",
      "Epoch 120/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.8531 - mean_squared_error: 84.8531\n",
      "Epoch 121/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.7689 - mean_squared_error: 85.7689\n",
      "Epoch 122/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.9442 - mean_squared_error: 84.9442\n",
      "Epoch 123/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.6404 - mean_squared_error: 85.6404\n",
      "Epoch 124/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.0244 - mean_squared_error: 85.0244\n",
      "Epoch 125/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.1091 - mean_squared_error: 85.1091\n",
      "Epoch 126/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.4748 - mean_squared_error: 85.4748\n",
      "Epoch 127/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.8782 - mean_squared_error: 85.8782\n",
      "Epoch 128/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 85.0747 - mean_squared_error: 85.0747\n",
      "Epoch 129/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.2666 - mean_squared_error: 85.2666\n",
      "Epoch 130/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.1888 - mean_squared_error: 85.1888\n",
      "Epoch 131/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.2130 - mean_squared_error: 85.2130\n",
      "Epoch 132/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 84.6154 - mean_squared_error: 84.6154\n",
      "Epoch 133/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.9958 - mean_squared_error: 84.9958\n",
      "Epoch 134/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.0678 - mean_squared_error: 85.0678\n",
      "Epoch 135/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.7094 - mean_squared_error: 84.7094\n",
      "Epoch 136/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.9481 - mean_squared_error: 84.9481\n",
      "Epoch 137/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.1520 - mean_squared_error: 85.1520\n",
      "Epoch 138/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.3930 - mean_squared_error: 85.3930\n",
      "Epoch 139/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.8964 - mean_squared_error: 84.8964\n",
      "Epoch 140/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 84.9530 - mean_squared_error: 84.9530\n",
      "Epoch 141/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 62us/step - loss: 85.3288 - mean_squared_error: 85.3288\n",
      "Epoch 142/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.0092 - mean_squared_error: 85.0092\n",
      "Epoch 143/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.2259 - mean_squared_error: 85.2259\n",
      "Epoch 144/5000\n",
      "506/506 [==============================] - 0s 80us/step - loss: 85.1957 - mean_squared_error: 85.1957\n",
      "Epoch 145/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.4370 - mean_squared_error: 85.4370\n",
      "Epoch 146/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.3190 - mean_squared_error: 85.3190\n",
      "Epoch 147/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.7632 - mean_squared_error: 85.7632\n",
      "Epoch 148/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.8774 - mean_squared_error: 84.8774\n",
      "Epoch 149/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.3631 - mean_squared_error: 85.3631\n",
      "Epoch 150/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.9701 - mean_squared_error: 84.9701\n",
      "Epoch 151/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.5819 - mean_squared_error: 85.5819\n",
      "Epoch 152/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.9883 - mean_squared_error: 84.9883\n",
      "Epoch 153/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.5349 - mean_squared_error: 84.5349\n",
      "Epoch 154/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 84.5096 - mean_squared_error: 84.5096\n",
      "Epoch 155/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.0800 - mean_squared_error: 85.0800\n",
      "Epoch 156/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.8302 - mean_squared_error: 84.8302\n",
      "Epoch 157/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.3333 - mean_squared_error: 85.3333\n",
      "Epoch 158/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 85.0880 - mean_squared_error: 85.0880\n",
      "Epoch 159/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 86.1177 - mean_squared_error: 86.1177\n",
      "Epoch 160/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.0748 - mean_squared_error: 85.0748\n",
      "Epoch 161/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.0227 - mean_squared_error: 85.0227\n",
      "Epoch 162/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.3481 - mean_squared_error: 85.3481\n",
      "Epoch 163/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.1629 - mean_squared_error: 85.1629\n",
      "Epoch 164/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.9194 - mean_squared_error: 84.9194\n",
      "Epoch 165/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.2581 - mean_squared_error: 85.2581\n",
      "Epoch 166/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.2600 - mean_squared_error: 85.2600\n",
      "Epoch 167/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 84.9868 - mean_squared_error: 84.9868\n",
      "Epoch 168/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.0238 - mean_squared_error: 85.0238\n",
      "Epoch 169/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.5384 - mean_squared_error: 85.5384\n",
      "Epoch 170/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.2228 - mean_squared_error: 84.2228\n",
      "Epoch 171/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.3065 - mean_squared_error: 85.3065\n",
      "Epoch 172/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.3533 - mean_squared_error: 84.3533\n",
      "Epoch 173/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.2767 - mean_squared_error: 85.2767\n",
      "Epoch 174/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 85.0150 - mean_squared_error: 85.0150\n",
      "Epoch 175/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.8051 - mean_squared_error: 84.8051\n",
      "Epoch 176/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 84.7357 - mean_squared_error: 84.7357\n",
      "Epoch 177/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.0936 - mean_squared_error: 85.0936\n",
      "Epoch 178/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.3993 - mean_squared_error: 85.3993\n",
      "Epoch 179/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.0618 - mean_squared_error: 85.0618\n",
      "Epoch 180/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 85.1448 - mean_squared_error: 85.1448\n",
      "Epoch 181/5000\n",
      "506/506 [==============================] - 0s 78us/step - loss: 85.4502 - mean_squared_error: 85.4502\n",
      "Epoch 182/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.6504 - mean_squared_error: 84.6504\n",
      "Epoch 183/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 84.7891 - mean_squared_error: 84.7891\n",
      "Epoch 184/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.9234 - mean_squared_error: 84.9234\n",
      "Epoch 185/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.8754 - mean_squared_error: 84.8754\n",
      "Epoch 186/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.6737 - mean_squared_error: 84.6737\n",
      "Epoch 187/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.1154 - mean_squared_error: 85.1154\n",
      "Epoch 188/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.9534 - mean_squared_error: 85.9534\n",
      "Epoch 189/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.1888 - mean_squared_error: 85.1888\n",
      "Epoch 190/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.6461 - mean_squared_error: 85.6461\n",
      "Epoch 191/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.4531 - mean_squared_error: 85.4531\n",
      "Epoch 192/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 84.9078 - mean_squared_error: 84.9078\n",
      "Epoch 193/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.5552 - mean_squared_error: 85.5552\n",
      "Epoch 194/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 84.2000 - mean_squared_error: 84.2000\n",
      "Epoch 195/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.3122 - mean_squared_error: 85.3122\n",
      "Epoch 196/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.1241 - mean_squared_error: 85.1241\n",
      "Epoch 197/5000\n",
      "506/506 [==============================] - 0s 38us/step - loss: 84.6246 - mean_squared_error: 84.6246\n",
      "Epoch 198/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.9514 - mean_squared_error: 84.9514\n",
      "Epoch 199/5000\n",
      "506/506 [==============================] - 0s 31us/step - loss: 85.6158 - mean_squared_error: 85.6158\n",
      "Epoch 200/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.9214 - mean_squared_error: 84.9214\n",
      "Epoch 201/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.9986 - mean_squared_error: 84.9986\n",
      "Epoch 202/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.7934 - mean_squared_error: 84.7934\n",
      "Epoch 203/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.2759 - mean_squared_error: 85.2759\n",
      "Epoch 204/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 84.9476 - mean_squared_error: 84.9476\n",
      "Epoch 205/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.7529 - mean_squared_error: 84.7529\n",
      "Epoch 206/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 84.6415 - mean_squared_error: 84.6415\n",
      "Epoch 207/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.2891 - mean_squared_error: 85.2891\n",
      "Epoch 208/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.0432 - mean_squared_error: 85.0432\n",
      "Epoch 209/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.8955 - mean_squared_error: 84.8955\n",
      "Epoch 210/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.2339 - mean_squared_error: 85.2339\n",
      "Epoch 211/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 54us/step - loss: 84.9909 - mean_squared_error: 84.9909\n",
      "Epoch 212/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.8783 - mean_squared_error: 84.8783\n",
      "Epoch 213/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.1552 - mean_squared_error: 85.1552\n",
      "Epoch 214/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.5238 - mean_squared_error: 85.5238\n",
      "Epoch 215/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.6824 - mean_squared_error: 85.6824\n",
      "Epoch 216/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.4589 - mean_squared_error: 85.4589\n",
      "Epoch 217/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 84.9196 - mean_squared_error: 84.9196\n",
      "Epoch 218/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 85.6688 - mean_squared_error: 85.6688\n",
      "Epoch 219/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 84.7067 - mean_squared_error: 84.7067\n",
      "Epoch 220/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.2773 - mean_squared_error: 85.2773\n",
      "Epoch 221/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.4952 - mean_squared_error: 85.4952\n",
      "Epoch 222/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.4957 - mean_squared_error: 85.4957\n",
      "Epoch 223/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.6457 - mean_squared_error: 85.6457\n",
      "Epoch 224/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.8547 - mean_squared_error: 84.8547\n",
      "Epoch 225/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 85.1250 - mean_squared_error: 85.1250\n",
      "Epoch 226/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.1111 - mean_squared_error: 85.1111\n",
      "Epoch 227/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.0247 - mean_squared_error: 85.0247\n",
      "Epoch 228/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.9390 - mean_squared_error: 84.9390\n",
      "Epoch 229/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.0400 - mean_squared_error: 85.0400\n",
      "Epoch 230/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 85.1800 - mean_squared_error: 85.1800\n",
      "Epoch 231/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.6167 - mean_squared_error: 85.6167\n",
      "Epoch 232/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.9130 - mean_squared_error: 85.9130\n",
      "Epoch 233/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.7820 - mean_squared_error: 84.7820\n",
      "Epoch 234/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.7864 - mean_squared_error: 84.7864\n",
      "Epoch 235/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.9280 - mean_squared_error: 84.9280\n",
      "Epoch 236/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.3473 - mean_squared_error: 85.3473\n",
      "Epoch 237/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.8159 - mean_squared_error: 84.8159\n",
      "Epoch 238/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.7411 - mean_squared_error: 84.7411\n",
      "Epoch 239/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.7734 - mean_squared_error: 84.7734\n",
      "Epoch 240/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 85.2056 - mean_squared_error: 85.2056\n",
      "Epoch 241/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.7248 - mean_squared_error: 84.7248\n",
      "Epoch 242/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 84.6175 - mean_squared_error: 84.6175\n",
      "Epoch 243/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.7081 - mean_squared_error: 84.7081\n",
      "Epoch 244/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 86.0801 - mean_squared_error: 86.0801\n",
      "Epoch 245/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.0040 - mean_squared_error: 85.0040\n",
      "Epoch 246/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.3627 - mean_squared_error: 85.3627\n",
      "Epoch 247/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 85.4428 - mean_squared_error: 85.4428\n",
      "Epoch 248/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.2151 - mean_squared_error: 85.2151\n",
      "Epoch 249/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.5661 - mean_squared_error: 84.5661\n",
      "Epoch 250/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.4826 - mean_squared_error: 85.4826\n",
      "Epoch 251/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.1821 - mean_squared_error: 85.1821\n",
      "Epoch 252/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 84.7725 - mean_squared_error: 84.7725\n",
      "Epoch 253/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 85.7255 - mean_squared_error: 85.7255\n",
      "Epoch 254/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.7034 - mean_squared_error: 85.7034\n",
      "Epoch 255/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.0612 - mean_squared_error: 85.0612\n",
      "Epoch 256/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 85.8056 - mean_squared_error: 85.8056\n",
      "Epoch 257/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.0539 - mean_squared_error: 85.0539\n",
      "Epoch 258/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 84.9245 - mean_squared_error: 84.9245\n",
      "Epoch 259/5000\n",
      "506/506 [==============================] - 0s 35us/step - loss: 84.6080 - mean_squared_error: 84.6080\n",
      "Epoch 260/5000\n",
      "506/506 [==============================] - 0s 36us/step - loss: 84.6883 - mean_squared_error: 84.6883\n",
      "Epoch 261/5000\n",
      "506/506 [==============================] - 0s 38us/step - loss: 84.2552 - mean_squared_error: 84.2552\n",
      "Epoch 262/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 84.7298 - mean_squared_error: 84.7298\n",
      "Epoch 263/5000\n",
      "506/506 [==============================] - 0s 30us/step - loss: 84.4470 - mean_squared_error: 84.4470\n",
      "Epoch 264/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.3399 - mean_squared_error: 84.3399\n",
      "Epoch 265/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 84.9714 - mean_squared_error: 84.9714\n",
      "Epoch 266/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.3199 - mean_squared_error: 84.3199\n",
      "Epoch 267/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.1250 - mean_squared_error: 84.1250\n",
      "Epoch 268/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.5904 - mean_squared_error: 85.5904\n",
      "Epoch 269/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.5772 - mean_squared_error: 85.5772\n",
      "Epoch 270/5000\n",
      "506/506 [==============================] - 0s 80us/step - loss: 85.7229 - mean_squared_error: 85.7229\n",
      "Epoch 271/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 85.2724 - mean_squared_error: 85.2724\n",
      "Epoch 272/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.2410 - mean_squared_error: 85.2410\n",
      "Epoch 273/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.0061 - mean_squared_error: 85.0061\n",
      "Epoch 274/5000\n",
      "506/506 [==============================] - 0s 76us/step - loss: 85.4766 - mean_squared_error: 85.4766\n",
      "Epoch 275/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.2656 - mean_squared_error: 85.2656\n",
      "Epoch 276/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.1145 - mean_squared_error: 85.1145\n",
      "Epoch 277/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.5018 - mean_squared_error: 85.5018\n",
      "Epoch 278/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.3132 - mean_squared_error: 85.3132\n",
      "Epoch 279/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.3549 - mean_squared_error: 85.3549\n",
      "Epoch 280/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.7881 - mean_squared_error: 84.7881\n",
      "Epoch 281/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 60us/step - loss: 84.9341 - mean_squared_error: 84.9341\n",
      "Epoch 282/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.3827 - mean_squared_error: 85.3827\n",
      "Epoch 283/5000\n",
      "506/506 [==============================] - 0s 85us/step - loss: 85.2546 - mean_squared_error: 85.2546\n",
      "Epoch 284/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.3267 - mean_squared_error: 85.3267\n",
      "Epoch 285/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.6884 - mean_squared_error: 84.6884\n",
      "Epoch 286/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.8015 - mean_squared_error: 84.8015\n",
      "Epoch 287/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 85.5370 - mean_squared_error: 85.5370\n",
      "Epoch 288/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 84.8321 - mean_squared_error: 84.8321\n",
      "Epoch 289/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.6124 - mean_squared_error: 84.6124\n",
      "Epoch 290/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.9399 - mean_squared_error: 84.9399\n",
      "Epoch 291/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.1516 - mean_squared_error: 85.1516\n",
      "Epoch 292/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.8563 - mean_squared_error: 84.8563\n",
      "Epoch 293/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.1439 - mean_squared_error: 85.1439\n",
      "Epoch 294/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.0365 - mean_squared_error: 85.0365\n",
      "Epoch 295/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 84.8047 - mean_squared_error: 84.8047\n",
      "Epoch 296/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 85.6976 - mean_squared_error: 85.6976\n",
      "Epoch 297/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.2605 - mean_squared_error: 85.2605\n",
      "Epoch 298/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.0323 - mean_squared_error: 85.0323\n",
      "Epoch 299/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.9834 - mean_squared_error: 84.9834\n",
      "Epoch 300/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.1969 - mean_squared_error: 85.1969\n",
      "Epoch 301/5000\n",
      "506/506 [==============================] - 0s 82us/step - loss: 85.3409 - mean_squared_error: 85.3409\n",
      "Epoch 302/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.2416 - mean_squared_error: 85.2416\n",
      "Epoch 303/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.0855 - mean_squared_error: 85.0855\n",
      "Epoch 304/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.0274 - mean_squared_error: 85.0274\n",
      "Epoch 305/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.9841 - mean_squared_error: 84.9841\n",
      "Epoch 306/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.1165 - mean_squared_error: 85.1165\n",
      "Epoch 307/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.0899 - mean_squared_error: 85.0899\n",
      "Epoch 308/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 85.6860 - mean_squared_error: 85.6860\n",
      "Epoch 309/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.3722 - mean_squared_error: 85.3722\n",
      "Epoch 310/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.0859 - mean_squared_error: 85.0859\n",
      "Epoch 311/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.0149 - mean_squared_error: 85.0149\n",
      "Epoch 312/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.5866 - mean_squared_error: 85.5866\n",
      "Epoch 313/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.6160 - mean_squared_error: 84.6160\n",
      "Epoch 314/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.5699 - mean_squared_error: 85.5699\n",
      "Epoch 315/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.8948 - mean_squared_error: 84.8948\n",
      "Epoch 316/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.1080 - mean_squared_error: 85.1080\n",
      "Epoch 317/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 85.0768 - mean_squared_error: 85.0768\n",
      "Epoch 318/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.9349 - mean_squared_error: 84.9349\n",
      "Epoch 319/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.7351 - mean_squared_error: 84.7351\n",
      "Epoch 320/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 84.8769 - mean_squared_error: 84.8769\n",
      "Epoch 321/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.6134 - mean_squared_error: 84.6134\n",
      "Epoch 322/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.5191 - mean_squared_error: 85.5191\n",
      "Epoch 323/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.8455 - mean_squared_error: 84.8455\n",
      "Epoch 324/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.7218 - mean_squared_error: 84.7218\n",
      "Epoch 325/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.4436 - mean_squared_error: 85.4436\n",
      "Epoch 326/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 84.9416 - mean_squared_error: 84.9416\n",
      "Epoch 327/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.1525 - mean_squared_error: 85.1525\n",
      "Epoch 328/5000\n",
      "506/506 [==============================] - 0s 34us/step - loss: 84.6063 - mean_squared_error: 84.6063\n",
      "Epoch 329/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.4591 - mean_squared_error: 84.4591\n",
      "Epoch 330/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 84.3519 - mean_squared_error: 84.3519\n",
      "Epoch 331/5000\n",
      "506/506 [==============================] - 0s 36us/step - loss: 85.1905 - mean_squared_error: 85.1905\n",
      "Epoch 332/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.9025 - mean_squared_error: 85.9025\n",
      "Epoch 333/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.1852 - mean_squared_error: 85.1852\n",
      "Epoch 334/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.1202 - mean_squared_error: 85.1202\n",
      "Epoch 335/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.1678 - mean_squared_error: 85.1678\n",
      "Epoch 336/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.4030 - mean_squared_error: 85.4030\n",
      "Epoch 337/5000\n",
      "506/506 [==============================] - 0s 78us/step - loss: 85.0505 - mean_squared_error: 85.0505\n",
      "Epoch 338/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.3045 - mean_squared_error: 85.3045\n",
      "Epoch 339/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.0607 - mean_squared_error: 85.0607\n",
      "Epoch 340/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.2910 - mean_squared_error: 85.2910\n",
      "Epoch 341/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.0728 - mean_squared_error: 85.0728\n",
      "Epoch 342/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 84.8269 - mean_squared_error: 84.8269\n",
      "Epoch 343/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.5151 - mean_squared_error: 84.5151\n",
      "Epoch 344/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.9824 - mean_squared_error: 84.9824\n",
      "Epoch 345/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.2161 - mean_squared_error: 84.2161\n",
      "Epoch 346/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.0528 - mean_squared_error: 85.0528\n",
      "Epoch 347/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.6075 - mean_squared_error: 84.6075\n",
      "Epoch 348/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.3505 - mean_squared_error: 85.3505\n",
      "Epoch 349/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.8880 - mean_squared_error: 84.8880\n",
      "Epoch 350/5000\n",
      "506/506 [==============================] - 0s 76us/step - loss: 85.2261 - mean_squared_error: 85.2261\n",
      "Epoch 351/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 61us/step - loss: 85.3702 - mean_squared_error: 85.3702\n",
      "Epoch 352/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.0057 - mean_squared_error: 85.0057\n",
      "Epoch 353/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.0804 - mean_squared_error: 85.0804\n",
      "Epoch 354/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.9107 - mean_squared_error: 84.9107\n",
      "Epoch 355/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.5194 - mean_squared_error: 85.5194\n",
      "Epoch 356/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 85.1383 - mean_squared_error: 85.1383\n",
      "Epoch 357/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.1880 - mean_squared_error: 85.1880\n",
      "Epoch 358/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.0883 - mean_squared_error: 85.0883\n",
      "Epoch 359/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.6324 - mean_squared_error: 85.6324\n",
      "Epoch 360/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.7612 - mean_squared_error: 84.7612\n",
      "Epoch 361/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 84.6326 - mean_squared_error: 84.6326\n",
      "Epoch 362/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.9346 - mean_squared_error: 84.9346\n",
      "Epoch 363/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.1272 - mean_squared_error: 85.1272\n",
      "Epoch 364/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.4425 - mean_squared_error: 85.4425\n",
      "Epoch 365/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.9985 - mean_squared_error: 84.9985\n",
      "Epoch 366/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 84.9196 - mean_squared_error: 84.9196\n",
      "Epoch 367/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.4997 - mean_squared_error: 85.4997\n",
      "Epoch 368/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.0356 - mean_squared_error: 85.0356\n",
      "Epoch 369/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.4109 - mean_squared_error: 85.4109\n",
      "Epoch 370/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 84.8147 - mean_squared_error: 84.8147\n",
      "Epoch 371/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.5061 - mean_squared_error: 85.5061\n",
      "Epoch 372/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.3744 - mean_squared_error: 85.3744\n",
      "Epoch 373/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.2461 - mean_squared_error: 85.2461\n",
      "Epoch 374/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.9414 - mean_squared_error: 85.9414\n",
      "Epoch 375/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.9860 - mean_squared_error: 84.9860\n",
      "Epoch 376/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.5856 - mean_squared_error: 85.5856\n",
      "Epoch 377/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.2628 - mean_squared_error: 85.2628\n",
      "Epoch 378/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.7506 - mean_squared_error: 84.7506\n",
      "Epoch 379/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 85.2636 - mean_squared_error: 85.2636\n",
      "Epoch 380/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.0772 - mean_squared_error: 85.0772\n",
      "Epoch 381/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 84.9477 - mean_squared_error: 84.9477\n",
      "Epoch 382/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 83.8538 - mean_squared_error: 83.8538\n",
      "Epoch 383/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.6319 - mean_squared_error: 85.6319\n",
      "Epoch 384/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.6929 - mean_squared_error: 84.6929\n",
      "Epoch 385/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.8580 - mean_squared_error: 84.8580\n",
      "Epoch 386/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.0482 - mean_squared_error: 85.0482\n",
      "Epoch 387/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.4390 - mean_squared_error: 85.4390\n",
      "Epoch 388/5000\n",
      "506/506 [==============================] - 0s 39us/step - loss: 85.2515 - mean_squared_error: 85.2515\n",
      "Epoch 389/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.9048 - mean_squared_error: 84.9048\n",
      "Epoch 390/5000\n",
      "506/506 [==============================] - 0s 35us/step - loss: 85.4900 - mean_squared_error: 85.4900\n",
      "Epoch 391/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.1968 - mean_squared_error: 85.1968\n",
      "Epoch 392/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.9025 - mean_squared_error: 84.9025\n",
      "Epoch 393/5000\n",
      "506/506 [==============================] - 0s 29us/step - loss: 85.4559 - mean_squared_error: 85.4559\n",
      "Epoch 394/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.8163 - mean_squared_error: 84.8163\n",
      "Epoch 395/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 84.9306 - mean_squared_error: 84.9306\n",
      "Epoch 396/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.9987 - mean_squared_error: 84.9987\n",
      "Epoch 397/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.7444 - mean_squared_error: 84.7444\n",
      "Epoch 398/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 84.8669 - mean_squared_error: 84.8669\n",
      "Epoch 399/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.0853 - mean_squared_error: 85.0853\n",
      "Epoch 400/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.1125 - mean_squared_error: 85.1125\n",
      "Epoch 401/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.0603 - mean_squared_error: 85.0603\n",
      "Epoch 402/5000\n",
      "506/506 [==============================] - 0s 78us/step - loss: 84.7569 - mean_squared_error: 84.7569\n",
      "Epoch 403/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.2764 - mean_squared_error: 85.2764\n",
      "Epoch 404/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 84.6954 - mean_squared_error: 84.6954\n",
      "Epoch 405/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.7624 - mean_squared_error: 84.7624\n",
      "Epoch 406/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.3811 - mean_squared_error: 85.3811\n",
      "Epoch 407/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 85.0101 - mean_squared_error: 85.0101\n",
      "Epoch 408/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.7591 - mean_squared_error: 84.7591\n",
      "Epoch 409/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.2854 - mean_squared_error: 85.2854\n",
      "Epoch 410/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.8419 - mean_squared_error: 84.8419\n",
      "Epoch 411/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.1085 - mean_squared_error: 85.1085\n",
      "Epoch 412/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.0138 - mean_squared_error: 85.0138\n",
      "Epoch 413/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.7308 - mean_squared_error: 84.7308\n",
      "Epoch 414/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.1141 - mean_squared_error: 85.1141\n",
      "Epoch 415/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.8894 - mean_squared_error: 84.8894\n",
      "Epoch 416/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.0264 - mean_squared_error: 85.0264\n",
      "Epoch 417/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.0151 - mean_squared_error: 85.0151\n",
      "Epoch 418/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.1810 - mean_squared_error: 85.1810\n",
      "Epoch 419/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.1758 - mean_squared_error: 85.1758\n",
      "Epoch 420/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.0854 - mean_squared_error: 85.0854\n",
      "Epoch 421/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 55us/step - loss: 85.0753 - mean_squared_error: 85.0753\n",
      "Epoch 422/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.9265 - mean_squared_error: 84.9265\n",
      "Epoch 423/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.6310 - mean_squared_error: 84.6310\n",
      "Epoch 424/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 85.5256 - mean_squared_error: 85.5256\n",
      "Epoch 425/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.1650 - mean_squared_error: 85.1650\n",
      "Epoch 426/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.7339 - mean_squared_error: 84.7339\n",
      "Epoch 427/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.3687 - mean_squared_error: 85.3687\n",
      "Epoch 428/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.2038 - mean_squared_error: 85.2038\n",
      "Epoch 429/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.2370 - mean_squared_error: 85.2370\n",
      "Epoch 430/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.1194 - mean_squared_error: 85.1194\n",
      "Epoch 431/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.0839 - mean_squared_error: 85.0839\n",
      "Epoch 432/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.0744 - mean_squared_error: 85.0744\n",
      "Epoch 433/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 84.9452 - mean_squared_error: 84.9452\n",
      "Epoch 434/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.7722 - mean_squared_error: 84.7722\n",
      "Epoch 435/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.3526 - mean_squared_error: 84.3526\n",
      "Epoch 436/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.8934 - mean_squared_error: 84.8934\n",
      "Epoch 437/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.1771 - mean_squared_error: 85.1771\n",
      "Epoch 438/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.8505 - mean_squared_error: 85.8505\n",
      "Epoch 439/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.2312 - mean_squared_error: 85.2312\n",
      "Epoch 440/5000\n",
      "506/506 [==============================] - 0s 78us/step - loss: 84.7058 - mean_squared_error: 84.7058\n",
      "Epoch 441/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.8922 - mean_squared_error: 84.8922\n",
      "Epoch 442/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.2877 - mean_squared_error: 85.2877\n",
      "Epoch 443/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.3687 - mean_squared_error: 85.3687\n",
      "Epoch 444/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.4699 - mean_squared_error: 84.4699\n",
      "Epoch 445/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 84.8794 - mean_squared_error: 84.8794\n",
      "Epoch 446/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.9447 - mean_squared_error: 85.9447\n",
      "Epoch 447/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.1875 - mean_squared_error: 85.1875\n",
      "Epoch 448/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.2198 - mean_squared_error: 85.2198\n",
      "Epoch 449/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.1721 - mean_squared_error: 85.1721\n",
      "Epoch 450/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 84.9713 - mean_squared_error: 84.9713\n",
      "Epoch 451/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.9216 - mean_squared_error: 84.9216\n",
      "Epoch 452/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.2792 - mean_squared_error: 85.2792\n",
      "Epoch 453/5000\n",
      "506/506 [==============================] - 0s 39us/step - loss: 85.1854 - mean_squared_error: 85.1854\n",
      "Epoch 454/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.8535 - mean_squared_error: 84.8535\n",
      "Epoch 455/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.2543 - mean_squared_error: 85.2543\n",
      "Epoch 456/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.8198 - mean_squared_error: 84.8198\n",
      "Epoch 457/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 85.1160 - mean_squared_error: 85.1160\n",
      "Epoch 458/5000\n",
      "506/506 [==============================] - 0s 36us/step - loss: 84.8453 - mean_squared_error: 84.8453\n",
      "Epoch 459/5000\n",
      "506/506 [==============================] - 0s 42us/step - loss: 85.0634 - mean_squared_error: 85.0634\n",
      "Epoch 460/5000\n",
      "506/506 [==============================] - 0s 37us/step - loss: 85.0207 - mean_squared_error: 85.0207\n",
      "Epoch 461/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.3412 - mean_squared_error: 85.3412\n",
      "Epoch 462/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 85.1133 - mean_squared_error: 85.1133\n",
      "Epoch 463/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.1258 - mean_squared_error: 85.1258\n",
      "Epoch 464/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.2434 - mean_squared_error: 85.2434\n",
      "Epoch 465/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.0385 - mean_squared_error: 85.0385\n",
      "Epoch 466/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 84.8871 - mean_squared_error: 84.8871\n",
      "Epoch 467/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.7723 - mean_squared_error: 84.7723\n",
      "Epoch 468/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.8237 - mean_squared_error: 84.8237\n",
      "Epoch 469/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.0156 - mean_squared_error: 85.0156\n",
      "Epoch 470/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.3914 - mean_squared_error: 85.3914\n",
      "Epoch 471/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.0241 - mean_squared_error: 85.0241\n",
      "Epoch 472/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.3331 - mean_squared_error: 85.3331\n",
      "Epoch 473/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 84.9645 - mean_squared_error: 84.9645\n",
      "Epoch 474/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.9994 - mean_squared_error: 84.9994\n",
      "Epoch 475/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 85.1748 - mean_squared_error: 85.1748\n",
      "Epoch 476/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.2521 - mean_squared_error: 85.2521\n",
      "Epoch 477/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 84.7670 - mean_squared_error: 84.7670\n",
      "Epoch 478/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.1218 - mean_squared_error: 85.1218\n",
      "Epoch 479/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.6921 - mean_squared_error: 84.6921\n",
      "Epoch 480/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.8119 - mean_squared_error: 84.8119\n",
      "Epoch 481/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.0991 - mean_squared_error: 85.0991\n",
      "Epoch 482/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.1323 - mean_squared_error: 85.1323\n",
      "Epoch 483/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 84.8712 - mean_squared_error: 84.8712\n",
      "Epoch 484/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.0935 - mean_squared_error: 85.0935\n",
      "Epoch 485/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.9640 - mean_squared_error: 84.9640\n",
      "Epoch 486/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.7345 - mean_squared_error: 84.7345\n",
      "Epoch 487/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.9644 - mean_squared_error: 84.9644\n",
      "Epoch 488/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.7320 - mean_squared_error: 84.7320\n",
      "Epoch 489/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 84.8364 - mean_squared_error: 84.8364\n",
      "Epoch 490/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.7497 - mean_squared_error: 84.7497\n",
      "Epoch 491/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 79us/step - loss: 85.2048 - mean_squared_error: 85.2048\n",
      "Epoch 492/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.9330 - mean_squared_error: 84.9330\n",
      "Epoch 493/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.4924 - mean_squared_error: 85.4924\n",
      "Epoch 494/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.7943 - mean_squared_error: 84.7943\n",
      "Epoch 495/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.0604 - mean_squared_error: 85.0604\n",
      "Epoch 496/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.1923 - mean_squared_error: 84.1923\n",
      "Epoch 497/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.1488 - mean_squared_error: 85.1488\n",
      "Epoch 498/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.8337 - mean_squared_error: 84.8337\n",
      "Epoch 499/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.2645 - mean_squared_error: 85.2645\n",
      "Epoch 500/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.4409 - mean_squared_error: 85.4409\n",
      "Epoch 501/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.9371 - mean_squared_error: 84.9371\n",
      "Epoch 502/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.9547 - mean_squared_error: 84.9547\n",
      "Epoch 503/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.0047 - mean_squared_error: 85.0047\n",
      "Epoch 504/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 84.5735 - mean_squared_error: 84.5735\n",
      "Epoch 505/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 84.8755 - mean_squared_error: 84.8755\n",
      "Epoch 506/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.4329 - mean_squared_error: 85.4329\n",
      "Epoch 507/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.7517 - mean_squared_error: 84.7517\n",
      "Epoch 508/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.4258 - mean_squared_error: 85.4258\n",
      "Epoch 509/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 85.5339 - mean_squared_error: 85.5339\n",
      "Epoch 510/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.4883 - mean_squared_error: 85.4883\n",
      "Epoch 511/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.8812 - mean_squared_error: 84.8812\n",
      "Epoch 512/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 84.9922 - mean_squared_error: 84.9922\n",
      "Epoch 513/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 84.7731 - mean_squared_error: 84.7731\n",
      "Epoch 514/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.0561 - mean_squared_error: 85.0561\n",
      "Epoch 515/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.9043 - mean_squared_error: 84.9043\n",
      "Epoch 516/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 85.2201 - mean_squared_error: 85.2201\n",
      "Epoch 517/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.7844 - mean_squared_error: 84.7844\n",
      "Epoch 518/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.0681 - mean_squared_error: 85.0681\n",
      "Epoch 519/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.1412 - mean_squared_error: 84.1412\n",
      "Epoch 520/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.0075 - mean_squared_error: 85.0075\n",
      "Epoch 521/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 84.7103 - mean_squared_error: 84.7103\n",
      "Epoch 522/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.2229 - mean_squared_error: 85.2229\n",
      "Epoch 523/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.4983 - mean_squared_error: 85.4983\n",
      "Epoch 524/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.3085 - mean_squared_error: 85.3085\n",
      "Epoch 525/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.3862 - mean_squared_error: 85.3862\n",
      "Epoch 526/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.6461 - mean_squared_error: 84.6461\n",
      "Epoch 527/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.9784 - mean_squared_error: 84.9784\n",
      "Epoch 528/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.7976 - mean_squared_error: 84.7976\n",
      "Epoch 529/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.7559 - mean_squared_error: 84.7559\n",
      "Epoch 530/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 84.9012 - mean_squared_error: 84.9012\n",
      "Epoch 531/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.5389 - mean_squared_error: 84.5389\n",
      "Epoch 532/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.2468 - mean_squared_error: 85.2468\n",
      "Epoch 533/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 84.8611 - mean_squared_error: 84.8611\n",
      "Epoch 534/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.1048 - mean_squared_error: 85.1048\n",
      "Epoch 535/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.6319 - mean_squared_error: 84.6319\n",
      "Epoch 536/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.1256 - mean_squared_error: 85.1256\n",
      "Epoch 537/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.0434 - mean_squared_error: 85.0434\n",
      "Epoch 538/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 84.9542 - mean_squared_error: 84.9542\n",
      "Epoch 539/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.6363 - mean_squared_error: 84.6363\n",
      "Epoch 540/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.5070 - mean_squared_error: 85.5070\n",
      "Epoch 541/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.3407 - mean_squared_error: 85.3407\n",
      "Epoch 542/5000\n",
      "506/506 [==============================] - 0s 78us/step - loss: 84.6764 - mean_squared_error: 84.6764\n",
      "Epoch 543/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.9557 - mean_squared_error: 84.9557\n",
      "Epoch 544/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.3978 - mean_squared_error: 85.3978\n",
      "Epoch 545/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 84.8902 - mean_squared_error: 84.8902\n",
      "Epoch 546/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.9339 - mean_squared_error: 84.9339\n",
      "Epoch 547/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.6350 - mean_squared_error: 85.6350\n",
      "Epoch 548/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.0126 - mean_squared_error: 85.0126\n",
      "Epoch 549/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 84.9165 - mean_squared_error: 84.9165\n",
      "Epoch 550/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.2469 - mean_squared_error: 85.2469\n",
      "Epoch 551/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.3298 - mean_squared_error: 85.3298\n",
      "Epoch 552/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.4393 - mean_squared_error: 84.4393\n",
      "Epoch 553/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.9972 - mean_squared_error: 84.9972\n",
      "Epoch 554/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.1924 - mean_squared_error: 85.1924\n",
      "Epoch 555/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.8038 - mean_squared_error: 84.8038\n",
      "Epoch 556/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.3118 - mean_squared_error: 85.3118\n",
      "Epoch 557/5000\n",
      "506/506 [==============================] - 0s 38us/step - loss: 84.5082 - mean_squared_error: 84.5082\n",
      "Epoch 558/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.2740 - mean_squared_error: 85.2740\n",
      "Epoch 559/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.6809 - mean_squared_error: 84.6809\n",
      "Epoch 560/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.3762 - mean_squared_error: 85.3762\n",
      "Epoch 561/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 53us/step - loss: 84.6124 - mean_squared_error: 84.6124\n",
      "Epoch 562/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.9155 - mean_squared_error: 84.9155\n",
      "Epoch 563/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 83.9864 - mean_squared_error: 83.9864\n",
      "Epoch 564/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.3675 - mean_squared_error: 85.3675\n",
      "Epoch 565/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.5496 - mean_squared_error: 85.5496\n",
      "Epoch 566/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.0878 - mean_squared_error: 85.0878\n",
      "Epoch 567/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.9054 - mean_squared_error: 84.9054\n",
      "Epoch 568/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.8235 - mean_squared_error: 84.8235\n",
      "Epoch 569/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.8601 - mean_squared_error: 84.8601\n",
      "Epoch 570/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.2488 - mean_squared_error: 85.2488\n",
      "Epoch 571/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.1858 - mean_squared_error: 85.1858\n",
      "Epoch 572/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.7306 - mean_squared_error: 85.7306\n",
      "Epoch 573/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.1365 - mean_squared_error: 85.1365\n",
      "Epoch 574/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 85.1728 - mean_squared_error: 85.1728\n",
      "Epoch 575/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.9805 - mean_squared_error: 84.9805\n",
      "Epoch 576/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.0374 - mean_squared_error: 85.0374\n",
      "Epoch 577/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.7582 - mean_squared_error: 84.7582\n",
      "Epoch 578/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.5105 - mean_squared_error: 85.5105\n",
      "Epoch 579/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.3064 - mean_squared_error: 85.3064\n",
      "Epoch 580/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 84.9920 - mean_squared_error: 84.9920\n",
      "Epoch 581/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 85.0318 - mean_squared_error: 85.0318\n",
      "Epoch 582/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.9203 - mean_squared_error: 84.9203\n",
      "Epoch 583/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 85.0566 - mean_squared_error: 85.0566\n",
      "Epoch 584/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.3086 - mean_squared_error: 85.3086\n",
      "Epoch 585/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.0530 - mean_squared_error: 85.0530\n",
      "Epoch 586/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.4914 - mean_squared_error: 84.4914\n",
      "Epoch 587/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 85.1921 - mean_squared_error: 85.1921\n",
      "Epoch 588/5000\n",
      "506/506 [==============================] - 0s 38us/step - loss: 84.9855 - mean_squared_error: 84.9855\n",
      "Epoch 589/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.0786 - mean_squared_error: 85.0786\n",
      "Epoch 590/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.0333 - mean_squared_error: 85.0333\n",
      "Epoch 591/5000\n",
      "506/506 [==============================] - 0s 38us/step - loss: 85.2291 - mean_squared_error: 85.2291\n",
      "Epoch 592/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.0306 - mean_squared_error: 85.0306\n",
      "Epoch 593/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.1346 - mean_squared_error: 85.1346\n",
      "Epoch 594/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.0157 - mean_squared_error: 85.0157\n",
      "Epoch 595/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.8854 - mean_squared_error: 84.8854\n",
      "Epoch 596/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.9842 - mean_squared_error: 84.9842\n",
      "Epoch 597/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.2347 - mean_squared_error: 85.2347\n",
      "Epoch 598/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 84.6959 - mean_squared_error: 84.6959\n",
      "Epoch 599/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.0931 - mean_squared_error: 85.0931\n",
      "Epoch 600/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.1203 - mean_squared_error: 85.1203\n",
      "Epoch 601/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.9623 - mean_squared_error: 84.9623\n",
      "Epoch 602/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.8528 - mean_squared_error: 84.8528\n",
      "Epoch 603/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.0210 - mean_squared_error: 85.0210\n",
      "Epoch 604/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.4549 - mean_squared_error: 85.4549\n",
      "Epoch 605/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.5828 - mean_squared_error: 85.5828\n",
      "Epoch 606/5000\n",
      "506/506 [==============================] - 0s 83us/step - loss: 85.1068 - mean_squared_error: 85.1068\n",
      "Epoch 607/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.8468 - mean_squared_error: 84.8468\n",
      "Epoch 608/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.3986 - mean_squared_error: 85.3986\n",
      "Epoch 609/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.7554 - mean_squared_error: 85.7554\n",
      "Epoch 610/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.1334 - mean_squared_error: 85.1334\n",
      "Epoch 611/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.4283 - mean_squared_error: 85.4283\n",
      "Epoch 612/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 84.7941 - mean_squared_error: 84.7941\n",
      "Epoch 613/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.0166 - mean_squared_error: 85.0166\n",
      "Epoch 614/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.8350 - mean_squared_error: 84.8350\n",
      "Epoch 615/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.3530 - mean_squared_error: 85.3530\n",
      "Epoch 616/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.8732 - mean_squared_error: 84.8732\n",
      "Epoch 617/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.5919 - mean_squared_error: 85.5919\n",
      "Epoch 618/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.1020 - mean_squared_error: 85.1020\n",
      "Epoch 619/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 85.0668 - mean_squared_error: 85.0668\n",
      "Epoch 620/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.0001 - mean_squared_error: 85.0001\n",
      "Epoch 621/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.9869 - mean_squared_error: 84.9869\n",
      "Epoch 622/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.3448 - mean_squared_error: 85.3448\n",
      "Epoch 623/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 84.7413 - mean_squared_error: 84.7413\n",
      "Epoch 624/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 85.2553 - mean_squared_error: 85.2553\n",
      "Epoch 625/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.8712 - mean_squared_error: 84.8712\n",
      "Epoch 626/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.1742 - mean_squared_error: 85.1742\n",
      "Epoch 627/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.9293 - mean_squared_error: 84.9293\n",
      "Epoch 628/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.8975 - mean_squared_error: 84.8975\n",
      "Epoch 629/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.2516 - mean_squared_error: 85.2516\n",
      "Epoch 630/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 84.4600 - mean_squared_error: 84.4600\n",
      "Epoch 631/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 57us/step - loss: 84.7186 - mean_squared_error: 84.7186\n",
      "Epoch 632/5000\n",
      "506/506 [==============================] - 0s 79us/step - loss: 85.0211 - mean_squared_error: 85.0211\n",
      "Epoch 633/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.1120 - mean_squared_error: 85.1120\n",
      "Epoch 634/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.1935 - mean_squared_error: 85.1935\n",
      "Epoch 635/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 84.9476 - mean_squared_error: 84.9476\n",
      "Epoch 636/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.9757 - mean_squared_error: 84.9757\n",
      "Epoch 637/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.0822 - mean_squared_error: 85.0822\n",
      "Epoch 638/5000\n",
      "506/506 [==============================] - 0s 42us/step - loss: 84.7716 - mean_squared_error: 84.7716\n",
      "Epoch 639/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.2566 - mean_squared_error: 85.2566\n",
      "Epoch 640/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.5930 - mean_squared_error: 85.5930\n",
      "Epoch 641/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.2887 - mean_squared_error: 85.2887\n",
      "Epoch 642/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.7400 - mean_squared_error: 84.7400\n",
      "Epoch 643/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 85.0331 - mean_squared_error: 85.0331\n",
      "Epoch 644/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 84.8263 - mean_squared_error: 84.8263\n",
      "Epoch 645/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.7995 - mean_squared_error: 84.7995\n",
      "Epoch 646/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 84.7763 - mean_squared_error: 84.7763\n",
      "Epoch 647/5000\n",
      "506/506 [==============================] - 0s 38us/step - loss: 85.3794 - mean_squared_error: 85.3794\n",
      "Epoch 648/5000\n",
      "506/506 [==============================] - 0s 44us/step - loss: 85.1992 - mean_squared_error: 85.1992\n",
      "Epoch 649/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.8043 - mean_squared_error: 84.8043\n",
      "Epoch 650/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 84.9649 - mean_squared_error: 84.9649\n",
      "Epoch 651/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 85.1290 - mean_squared_error: 85.1290\n",
      "Epoch 652/5000\n",
      "506/506 [==============================] - 0s 36us/step - loss: 85.0797 - mean_squared_error: 85.0797\n",
      "Epoch 653/5000\n",
      "506/506 [==============================] - 0s 32us/step - loss: 84.9903 - mean_squared_error: 84.9903\n",
      "Epoch 654/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.4107 - mean_squared_error: 85.4107\n",
      "Epoch 655/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 84.2887 - mean_squared_error: 84.2887\n",
      "Epoch 656/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 85.7565 - mean_squared_error: 85.7565\n",
      "Epoch 657/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 85.0065 - mean_squared_error: 85.0065\n",
      "Epoch 658/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 84.7313 - mean_squared_error: 84.7313\n",
      "Epoch 659/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.8326 - mean_squared_error: 84.8326\n",
      "Epoch 660/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.7851 - mean_squared_error: 84.7851\n",
      "Epoch 661/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.4938 - mean_squared_error: 84.4938\n",
      "Epoch 662/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 84.8061 - mean_squared_error: 84.8061\n",
      "Epoch 663/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.1291 - mean_squared_error: 85.1291\n",
      "Epoch 664/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.3228 - mean_squared_error: 85.3228\n",
      "Epoch 665/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.6370 - mean_squared_error: 84.6370\n",
      "Epoch 666/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.4276 - mean_squared_error: 85.4276\n",
      "Epoch 667/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 84.7960 - mean_squared_error: 84.7960\n",
      "Epoch 668/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.4543 - mean_squared_error: 85.4543\n",
      "Epoch 669/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.1439 - mean_squared_error: 85.1439\n",
      "Epoch 670/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.8679 - mean_squared_error: 84.8679\n",
      "Epoch 671/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.2755 - mean_squared_error: 84.2755\n",
      "Epoch 672/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 84.5012 - mean_squared_error: 84.5012\n",
      "Epoch 673/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.5569 - mean_squared_error: 85.5569\n",
      "Epoch 674/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.1736 - mean_squared_error: 85.1736\n",
      "Epoch 675/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.8000 - mean_squared_error: 85.8000\n",
      "Epoch 676/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.8245 - mean_squared_error: 84.8245\n",
      "Epoch 677/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.4497 - mean_squared_error: 85.4497\n",
      "Epoch 678/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.1074 - mean_squared_error: 85.1074\n",
      "Epoch 679/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.7975 - mean_squared_error: 85.7975\n",
      "Epoch 680/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.1969 - mean_squared_error: 85.1969\n",
      "Epoch 681/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.9737 - mean_squared_error: 84.9737\n",
      "Epoch 682/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.2692 - mean_squared_error: 84.2692\n",
      "Epoch 683/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.4417 - mean_squared_error: 85.4417\n",
      "Epoch 684/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.9669 - mean_squared_error: 84.9669\n",
      "Epoch 685/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.0907 - mean_squared_error: 85.0907\n",
      "Epoch 686/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.9119 - mean_squared_error: 84.9119\n",
      "Epoch 687/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.4236 - mean_squared_error: 85.4236\n",
      "Epoch 688/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 85.0960 - mean_squared_error: 85.0960\n",
      "Epoch 689/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.6211 - mean_squared_error: 85.6211\n",
      "Epoch 690/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.4630 - mean_squared_error: 85.4630\n",
      "Epoch 691/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 85.0027 - mean_squared_error: 85.0027\n",
      "Epoch 692/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.1503 - mean_squared_error: 85.1503\n",
      "Epoch 693/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.9806 - mean_squared_error: 84.9806\n",
      "Epoch 694/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.9074 - mean_squared_error: 84.9074\n",
      "Epoch 695/5000\n",
      "506/506 [==============================] - 0s 83us/step - loss: 84.1275 - mean_squared_error: 84.1275\n",
      "Epoch 696/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.4892 - mean_squared_error: 85.4892\n",
      "Epoch 697/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.8374 - mean_squared_error: 84.8374\n",
      "Epoch 698/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.7229 - mean_squared_error: 85.7229\n",
      "Epoch 699/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 83.9450 - mean_squared_error: 83.9450\n",
      "Epoch 700/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.0931 - mean_squared_error: 84.0931\n",
      "Epoch 701/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 66us/step - loss: 85.0464 - mean_squared_error: 85.0464\n",
      "Epoch 702/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 85.1333 - mean_squared_error: 85.1333\n",
      "Epoch 703/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.9138 - mean_squared_error: 84.9138\n",
      "Epoch 704/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 86.4281 - mean_squared_error: 86.4281\n",
      "Epoch 705/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.3473 - mean_squared_error: 85.3473\n",
      "Epoch 706/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.4789 - mean_squared_error: 84.4789\n",
      "Epoch 707/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.0255 - mean_squared_error: 85.0255\n",
      "Epoch 708/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 85.2653 - mean_squared_error: 85.2653\n",
      "Epoch 709/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.7243 - mean_squared_error: 84.7243\n",
      "Epoch 710/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.7536 - mean_squared_error: 84.7536\n",
      "Epoch 711/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.0770 - mean_squared_error: 85.0770\n",
      "Epoch 712/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.4868 - mean_squared_error: 85.4868\n",
      "Epoch 713/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.7760 - mean_squared_error: 84.7760\n",
      "Epoch 714/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.2507 - mean_squared_error: 85.2507\n",
      "Epoch 715/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.8326 - mean_squared_error: 84.8326\n",
      "Epoch 716/5000\n",
      "506/506 [==============================] - 0s 41us/step - loss: 85.1067 - mean_squared_error: 85.1067\n",
      "Epoch 717/5000\n",
      "506/506 [==============================] - 0s 35us/step - loss: 85.1139 - mean_squared_error: 85.1139\n",
      "Epoch 718/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 85.2626 - mean_squared_error: 85.2626\n",
      "Epoch 719/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 84.4346 - mean_squared_error: 84.4346\n",
      "Epoch 720/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 84.8405 - mean_squared_error: 84.8405\n",
      "Epoch 721/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.9692 - mean_squared_error: 84.9692\n",
      "Epoch 722/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.4911 - mean_squared_error: 85.4911\n",
      "Epoch 723/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.8635 - mean_squared_error: 84.8635\n",
      "Epoch 724/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.7287 - mean_squared_error: 84.7287\n",
      "Epoch 725/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.1936 - mean_squared_error: 85.1936\n",
      "Epoch 726/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.0986 - mean_squared_error: 85.0986\n",
      "Epoch 727/5000\n",
      "506/506 [==============================] - 0s 84us/step - loss: 84.7897 - mean_squared_error: 84.7897\n",
      "Epoch 728/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.7557 - mean_squared_error: 84.7557\n",
      "Epoch 729/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.8337 - mean_squared_error: 84.8337\n",
      "Epoch 730/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.0637 - mean_squared_error: 85.0637\n",
      "Epoch 731/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.1385 - mean_squared_error: 85.1385\n",
      "Epoch 732/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.6833 - mean_squared_error: 85.6833\n",
      "Epoch 733/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.1485 - mean_squared_error: 85.1485\n",
      "Epoch 734/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.9510 - mean_squared_error: 84.9510\n",
      "Epoch 735/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.6512 - mean_squared_error: 84.6512\n",
      "Epoch 736/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.2903 - mean_squared_error: 85.2903\n",
      "Epoch 737/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.5808 - mean_squared_error: 85.5808\n",
      "Epoch 738/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 84.7466 - mean_squared_error: 84.7466\n",
      "Epoch 739/5000\n",
      "506/506 [==============================] - 0s 46us/step - loss: 84.8433 - mean_squared_error: 84.8433\n",
      "Epoch 740/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.7025 - mean_squared_error: 85.7025\n",
      "Epoch 741/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.5990 - mean_squared_error: 84.5990\n",
      "Epoch 742/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.2569 - mean_squared_error: 85.2569\n",
      "Epoch 743/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 84.9941 - mean_squared_error: 84.9941\n",
      "Epoch 744/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.0077 - mean_squared_error: 85.0077\n",
      "Epoch 745/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.1743 - mean_squared_error: 85.1743\n",
      "Epoch 746/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.3058 - mean_squared_error: 85.3058\n",
      "Epoch 747/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.8694 - mean_squared_error: 84.8694\n",
      "Epoch 748/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.0664 - mean_squared_error: 85.0664\n",
      "Epoch 749/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.3977 - mean_squared_error: 85.3977\n",
      "Epoch 750/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 84.7909 - mean_squared_error: 84.7909\n",
      "Epoch 751/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.1910 - mean_squared_error: 85.1910\n",
      "Epoch 752/5000\n",
      "506/506 [==============================] - 0s 84us/step - loss: 84.8493 - mean_squared_error: 84.8493\n",
      "Epoch 753/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.0491 - mean_squared_error: 85.0491\n",
      "Epoch 754/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 84.9392 - mean_squared_error: 84.9392\n",
      "Epoch 755/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 84.9526 - mean_squared_error: 84.9526\n",
      "Epoch 756/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.9914 - mean_squared_error: 84.9914\n",
      "Epoch 757/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.0195 - mean_squared_error: 85.0195\n",
      "Epoch 758/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 85.1756 - mean_squared_error: 85.1756\n",
      "Epoch 759/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 85.4699 - mean_squared_error: 85.4699\n",
      "Epoch 760/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 85.7663 - mean_squared_error: 85.7663\n",
      "Epoch 761/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.6640 - mean_squared_error: 84.6640\n",
      "Epoch 762/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.7949 - mean_squared_error: 84.7949\n",
      "Epoch 763/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.4048 - mean_squared_error: 85.4048\n",
      "Epoch 764/5000\n",
      "506/506 [==============================] - 0s 71us/step - loss: 85.5702 - mean_squared_error: 85.5702\n",
      "Epoch 765/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.9354 - mean_squared_error: 84.9354\n",
      "Epoch 766/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.5109 - mean_squared_error: 85.5109\n",
      "Epoch 767/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.0776 - mean_squared_error: 85.0776\n",
      "Epoch 768/5000\n",
      "506/506 [==============================] - 0s 50us/step - loss: 85.0058 - mean_squared_error: 85.0058\n",
      "Epoch 769/5000\n",
      "506/506 [==============================] - 0s 42us/step - loss: 85.2969 - mean_squared_error: 85.2969\n",
      "Epoch 770/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.8832 - mean_squared_error: 84.8832\n",
      "Epoch 771/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 52us/step - loss: 84.8576 - mean_squared_error: 84.8576\n",
      "Epoch 772/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.9224 - mean_squared_error: 84.9224\n",
      "Epoch 773/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 84.8505 - mean_squared_error: 84.8505\n",
      "Epoch 774/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.3900 - mean_squared_error: 85.3900\n",
      "Epoch 775/5000\n",
      "506/506 [==============================] - 0s 55us/step - loss: 85.3227 - mean_squared_error: 85.3227\n",
      "Epoch 776/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 84.9115 - mean_squared_error: 84.9115\n",
      "Epoch 777/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.5220 - mean_squared_error: 85.5220\n",
      "Epoch 778/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 85.1809 - mean_squared_error: 85.1809\n",
      "Epoch 779/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.8795 - mean_squared_error: 84.8795\n",
      "Epoch 780/5000\n",
      "506/506 [==============================] - 0s 38us/step - loss: 84.4430 - mean_squared_error: 84.4430\n",
      "Epoch 781/5000\n",
      "506/506 [==============================] - 0s 47us/step - loss: 84.8322 - mean_squared_error: 84.8322\n",
      "Epoch 782/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.0883 - mean_squared_error: 85.0883\n",
      "Epoch 783/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.2008 - mean_squared_error: 85.2008\n",
      "Epoch 784/5000\n",
      "506/506 [==============================] - 0s 79us/step - loss: 85.4426 - mean_squared_error: 85.4426\n",
      "Epoch 785/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.1575 - mean_squared_error: 85.1575\n",
      "Epoch 786/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.3949 - mean_squared_error: 85.3949\n",
      "Epoch 787/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 84.7248 - mean_squared_error: 84.7248\n",
      "Epoch 788/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 84.5165 - mean_squared_error: 84.5165\n",
      "Epoch 789/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.8223 - mean_squared_error: 85.8223\n",
      "Epoch 790/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 84.5613 - mean_squared_error: 84.5613\n",
      "Epoch 791/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.0764 - mean_squared_error: 85.0764\n",
      "Epoch 792/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.9440 - mean_squared_error: 84.9440\n",
      "Epoch 793/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.1307 - mean_squared_error: 85.1307\n",
      "Epoch 794/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.3595 - mean_squared_error: 85.3595\n",
      "Epoch 795/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 85.3420 - mean_squared_error: 85.3420\n",
      "Epoch 796/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.2258 - mean_squared_error: 85.2258\n",
      "Epoch 797/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.1122 - mean_squared_error: 85.1122\n",
      "Epoch 798/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.6405 - mean_squared_error: 84.6405\n",
      "Epoch 799/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 85.1045 - mean_squared_error: 85.1045\n",
      "Epoch 800/5000\n",
      "506/506 [==============================] - 0s 86us/step - loss: 84.7714 - mean_squared_error: 84.7714\n",
      "Epoch 801/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.6239 - mean_squared_error: 84.6239\n",
      "Epoch 802/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.2767 - mean_squared_error: 85.2767\n",
      "Epoch 803/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 85.0245 - mean_squared_error: 85.0245\n",
      "Epoch 804/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 85.4369 - mean_squared_error: 85.4369\n",
      "Epoch 805/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.9814 - mean_squared_error: 84.9814\n",
      "Epoch 806/5000\n",
      "506/506 [==============================] - 0s 83us/step - loss: 84.7946 - mean_squared_error: 84.7946\n",
      "Epoch 807/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 84.6439 - mean_squared_error: 84.6439\n",
      "Epoch 808/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.3649 - mean_squared_error: 85.3649\n",
      "Epoch 809/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 84.8043 - mean_squared_error: 84.8043\n",
      "Epoch 810/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.3300 - mean_squared_error: 85.3300\n",
      "Epoch 811/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 85.1808 - mean_squared_error: 85.1808\n",
      "Epoch 812/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 85.2849 - mean_squared_error: 85.2849\n",
      "Epoch 813/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 84.8549 - mean_squared_error: 84.8549\n",
      "Epoch 814/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 84.2107 - mean_squared_error: 84.2107\n",
      "Epoch 815/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.4359 - mean_squared_error: 85.4359\n",
      "Epoch 816/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 84.6240 - mean_squared_error: 84.6240\n",
      "Epoch 817/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 84.8233 - mean_squared_error: 84.8233\n",
      "Epoch 818/5000\n",
      "506/506 [==============================] - 0s 64us/step - loss: 84.7857 - mean_squared_error: 84.7857\n",
      "Epoch 819/5000\n",
      "506/506 [==============================] - 0s 48us/step - loss: 85.0566 - mean_squared_error: 85.0566\n",
      "Epoch 820/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 84.9009 - mean_squared_error: 84.9009\n",
      "Epoch 821/5000\n",
      "506/506 [==============================] - 0s 62us/step - loss: 84.3690 - mean_squared_error: 84.3690\n",
      "Epoch 822/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.4110 - mean_squared_error: 85.4110\n",
      "Epoch 823/5000\n",
      "506/506 [==============================] - 0s 79us/step - loss: 85.1906 - mean_squared_error: 85.1906\n",
      "Epoch 824/5000\n",
      "506/506 [==============================] - 0s 75us/step - loss: 85.1292 - mean_squared_error: 85.1292\n",
      "Epoch 825/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 85.2271 - mean_squared_error: 85.2271\n",
      "Epoch 826/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 85.2493 - mean_squared_error: 85.2493\n",
      "Epoch 827/5000\n",
      "506/506 [==============================] - 0s 81us/step - loss: 85.1880 - mean_squared_error: 85.1880\n",
      "Epoch 828/5000\n",
      "506/506 [==============================] - 0s 60us/step - loss: 85.9106 - mean_squared_error: 85.9106\n",
      "Epoch 829/5000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 85.0184 - mean_squared_error: 85.0184\n",
      "Epoch 830/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 85.3175 - mean_squared_error: 85.3175\n",
      "Epoch 831/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 84.9374 - mean_squared_error: 84.9374\n",
      "Epoch 832/5000\n",
      "506/506 [==============================] - 0s 45us/step - loss: 84.7521 - mean_squared_error: 84.7521\n",
      "Epoch 833/5000\n",
      "506/506 [==============================] - 0s 40us/step - loss: 85.9284 - mean_squared_error: 85.9284\n",
      "Epoch 834/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.3400 - mean_squared_error: 85.3400\n",
      "Epoch 835/5000\n",
      "506/506 [==============================] - 0s 32us/step - loss: 84.6397 - mean_squared_error: 84.6397\n",
      "Epoch 836/5000\n",
      "506/506 [==============================] - 0s 53us/step - loss: 85.2071 - mean_squared_error: 85.2071\n",
      "Epoch 837/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 85.5312 - mean_squared_error: 85.5312\n",
      "Epoch 838/5000\n",
      "506/506 [==============================] - 0s 57us/step - loss: 85.3524 - mean_squared_error: 85.3524\n",
      "Epoch 839/5000\n",
      "506/506 [==============================] - 0s 43us/step - loss: 85.5963 - mean_squared_error: 85.5963\n",
      "Epoch 840/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 85.2281 - mean_squared_error: 85.2281\n",
      "Epoch 841/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 44us/step - loss: 85.5057 - mean_squared_error: 85.5057\n",
      "Epoch 842/5000\n",
      "506/506 [==============================] - 0s 69us/step - loss: 85.2541 - mean_squared_error: 85.2541\n",
      "Epoch 843/5000\n",
      "506/506 [==============================] - 0s 85us/step - loss: 85.0925 - mean_squared_error: 85.0925\n",
      "Epoch 844/5000\n",
      "506/506 [==============================] - 0s 59us/step - loss: 85.0701 - mean_squared_error: 85.0701\n",
      "Epoch 845/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.4431 - mean_squared_error: 85.4431\n",
      "Epoch 846/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 84.5982 - mean_squared_error: 84.5982\n",
      "Epoch 847/5000\n",
      "506/506 [==============================] - 0s 51us/step - loss: 85.2270 - mean_squared_error: 85.2270\n",
      "Epoch 848/5000\n",
      "506/506 [==============================] - 0s 82us/step - loss: 84.3814 - mean_squared_error: 84.3814\n",
      "Epoch 849/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 85.6030 - mean_squared_error: 85.6030\n",
      "Epoch 850/5000\n",
      "506/506 [==============================] - 0s 63us/step - loss: 84.9207 - mean_squared_error: 84.9207\n",
      "Epoch 851/5000\n",
      "506/506 [==============================] - 0s 52us/step - loss: 85.1606 - mean_squared_error: 85.1606\n",
      "Epoch 852/5000\n",
      "506/506 [==============================] - 0s 49us/step - loss: 84.5196 - mean_squared_error: 84.5196\n",
      "Epoch 853/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.0348 - mean_squared_error: 85.0348\n",
      "Epoch 854/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.9431 - mean_squared_error: 84.9431\n",
      "Epoch 855/5000\n",
      "506/506 [==============================] - 0s 92us/step - loss: 85.7173 - mean_squared_error: 85.7173\n",
      "Epoch 856/5000\n",
      "506/506 [==============================] - 0s 67us/step - loss: 86.4319 - mean_squared_error: 86.4319\n",
      "Epoch 857/5000\n",
      "506/506 [==============================] - 0s 70us/step - loss: 84.0116 - mean_squared_error: 84.0116\n",
      "Epoch 858/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 85.2035 - mean_squared_error: 85.2035\n",
      "Epoch 859/5000\n",
      "506/506 [==============================] - 0s 73us/step - loss: 85.5599 - mean_squared_error: 85.5599\n",
      "Epoch 860/5000\n",
      "506/506 [==============================] - 0s 68us/step - loss: 84.7681 - mean_squared_error: 84.7681\n",
      "Epoch 861/5000\n",
      "506/506 [==============================] - 0s 74us/step - loss: 85.4218 - mean_squared_error: 85.4218\n",
      "Epoch 862/5000\n",
      "506/506 [==============================] - 0s 58us/step - loss: 84.7874 - mean_squared_error: 84.7874\n",
      "Epoch 863/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 84.9071 - mean_squared_error: 84.9071\n",
      "Epoch 864/5000\n",
      "506/506 [==============================] - 0s 56us/step - loss: 85.0126 - mean_squared_error: 85.0126\n",
      "Epoch 865/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.3316 - mean_squared_error: 85.3316\n",
      "Epoch 866/5000\n",
      "506/506 [==============================] - 0s 66us/step - loss: 86.1034 - mean_squared_error: 86.1034\n",
      "Epoch 867/5000\n",
      "506/506 [==============================] - 0s 77us/step - loss: 84.9592 - mean_squared_error: 84.9592\n",
      "Epoch 868/5000\n",
      "506/506 [==============================] - 0s 65us/step - loss: 85.2852 - mean_squared_error: 85.2852\n",
      "Epoch 869/5000\n",
      "506/506 [==============================] - 0s 54us/step - loss: 85.0593 - mean_squared_error: 85.0593\n",
      "Epoch 870/5000\n",
      "506/506 [==============================] - 0s 61us/step - loss: 85.1429 - mean_squared_error: 85.1429\n",
      "Epoch 871/5000\n",
      " 32/506 [>.............................] - ETA: 0s - loss: 121.2959 - mean_squared_error: 121.2959"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-46d3f58551a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_, y_, epochs=5000, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
