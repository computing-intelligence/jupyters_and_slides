{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬虫 2017年的所有的新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_9k.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls article_9k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内\u001b[m测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精\u001b[m力主要用到MIUI9的研发之中MIUI8去年5月发布距今已有一年有余也是时候更新换代了当然\u001b[m\n",
      "关于MIUI9的确切信息我们还是等待官方消息\u001b[m\n",
      "骁龙835作为唯一通过Windows10桌面平台认证的ARM处理器高通强调不会因为只考虑性能而\u001b[m\n",
      "去屏蔽掉小核心相反他们正联手微软找到一种适合桌面平台的兼顾性能和功耗的完美方案报\u001b[m道称微软已经拿到了一些新的源码以便Windows10更好地理解biglittle架构资料显示骁龙83\u001b[m5作为一款集成了CPUGPU基带蓝牙WiFi的SoC比传统的Wintel方案可以节省至少30的PCB空间\u001b[m\n",
      "按计划今年Q4华硕惠普联想将首发骁龙835Win10电脑预计均是二合一形态的产品当然高通骁\u001b[m龙只是个开始未来也许还能见到三星Exynos联发科华为麒麟小米澎湃等进入Windows10桌面\u001b[m\n",
      "平台\u001b[m\n",
      "此前的一加3T搭载的是3400mAh电池DashCharge快充规格为5V4A至于电池缩水可能与刘作虎\u001b[m\n",
      "所说一加手机5要做市面最轻薄大屏旗舰的设定有关按照目前掌握的资料一加手机5拥有55寸\u001b[m1080P三星AMOLED显示屏6G8GBRAM64GB128GBROM双1600万摄像头备货量惊喜根据京东泄露的\u001b[m\n",
      "信息一加5起售价是xx99元应该是在279928992999中的某个\u001b[m\n",
      "这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车新华社记者张立云\u001b[m\n",
      "摄\u001b[m\n",
      "\u001b[K向的逆行辅道上发现该女子女子身上一丝不挂地逆车流而行时走时停时坐时躺险象环生刘青\u001b[m:\u001b[K行走在南坪快速上期间还起了轻生年头一辅警发现后赶紧为其披上黄衣并一路\u001b[m劝说她那么事发时到底都发生了些什么呢南都记者带您一起还原现场南都记者在龙岗大队坂\u001b[m田中队见到了辅警刘青发现女生的辅警一位外表高大帅气说话略带些腼腆的90后青年刘青介\u001b[m绍6月16日早上7时36分他正在环城南路附近值勤接到中队关于一位女子裸身进入机动车可能\u001b[m有危险的警情随后骑着小铁骑开始沿路寻找大概花了十多分钟在南坪大道坂田出口往龙岗方\u001b[m\u001b[7marticle_9k.txt\u001b[m\u001b[K\u0007"
     ]
    }
   ],
   "source": [
    "!less article_9k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_dataset = 'article_9k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHINESE_CHARATERS = open(chinese_dataset).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外自本周6月12日'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHINESE_CHARATERS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33425826"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHINESE_CHARATERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ni hao'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinyin.get('你好', format=\"strip\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_to_pinyin(character):\n",
    "    return pinyin.get(character, format=\"strip\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ni hao ma ？'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_to_pinyin('你好吗？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHINESE_PINYIN_CORPYS = chinese_to_pinyin(CHINESE_CHARATERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ci wai zi ben zhou 6 yue 1 2 ri qi chu xiao mi shou ji 6 deng 1 5 kuan ji xing wai qi yu ji xing yi '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHINESE_PINYIN_CORPYS[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    \"List all the pinyin characrters\"\n",
    "    return re.findall('[a-z]+', text.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_strange_str = \"1st You are a very very .... strange man!!! \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['st', 'you', 'are', 'a', 'very', 'very', 'strange', 'man']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens(some_strange_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = tokens(CHINESE_PINYIN_CORPYS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 没有一个叫做“常量”的东西，const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINYIN_COUNT = Counter(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shi', 860634),\n",
       " ('de', 809887),\n",
       " ('yi', 682478),\n",
       " ('ji', 645276),\n",
       " ('guo', 430042),\n",
       " ('zhong', 409418),\n",
       " ('zhi', 398612),\n",
       " ('xin', 359619),\n",
       " ('li', 355441),\n",
       " ('zai', 334106),\n",
       " ('wei', 326301),\n",
       " ('hua', 304941),\n",
       " ('yu', 302949),\n",
       " ('she', 293312),\n",
       " ('he', 285689),\n",
       " ('bu', 281533),\n",
       " ('ri', 278379),\n",
       " ('jin', 278141),\n",
       " ('you', 277726),\n",
       " ('xian', 269047)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINYIN_COUNT.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lanauge Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input: string\n",
    "+ output:  0 ~ 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ String -> word_0 word_1 word_2 $$\n",
    "\n",
    "$$ Pr(string) = Pr(w_0 w_1 w_2 w_3)         $$\n",
    "$$ 2-gram Pr(w_0 w_1 w_2 w_3)  = \\frac{Pr(w_0 w_1)}{Pr(w_1)} \\cdot \\frac{Pr(w_1 w_2)}{Pr(w_2)} \\cdot \\frac{Pr(w_2 w_3)}{Pr(w_3)} \\cdot Pr(w_3) $$\n",
    "$$ 1-gram Pr(w_0 w_1 w_2 w_3)  = Pr(w_0) \\dots \n",
    "Pr(w_3) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_one_word(word):\n",
    "    total = sum(PINYIN_COUNT.values())\n",
    "    if word in PINYIN_COUNT: \n",
    "        return PINYIN_COUNT[word] / total\n",
    "    else:\n",
    "        return min(PINYIN_COUNT.values()) / total # Out Of Vacabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001348378327943515"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_one_word('ni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _1_gram_prob_words(words):\n",
    "    return reduce(op.mul, [prob_one_word(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2_gram_words = [\n",
    "    TOKENS[i] + TOKENS[i+1] for i in range(len(TOKENS)-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ciwai',\n",
       " 'waizi',\n",
       " 'ziben',\n",
       " 'benzhou',\n",
       " 'zhouyue',\n",
       " 'yueri',\n",
       " 'riqi',\n",
       " 'qichu',\n",
       " 'chuxiao',\n",
       " 'xiaomi']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2_gram_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2_GRAM_COUNT = Counter(_2_gram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2_word(word):\n",
    "    total = sum(_2_GRAM_COUNT.values())\n",
    "    if word in _2_GRAM_COUNT: \n",
    "        return _2_GRAM_COUNT[word] / total\n",
    "    else:\n",
    "        return min(_2_GRAM_COUNT.values()) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3894212198744405e-06"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2_word('wocai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8969958728360782e-05"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2_word('woxiang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.354404533689823e-06"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2_word('wolai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _2_gram_model(words: str):\n",
    "    \n",
    "    words = words.split()\n",
    "    \n",
    "    prob = 1\n",
    "    \n",
    "    for i in range(len(words) - 1):\n",
    "        word = words[i]\n",
    "        next_word = words[i+1]\n",
    "        \n",
    "        _two_gram_prob = prob_2_word(word+next_word)\n",
    "        _one_gram_prob = prob_one_word(next_word)\n",
    "        \n",
    "        prob *= _two_gram_prob / _one_gram_prob\n",
    "    \n",
    "    prob *= prob_one_word(words[-1])\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = 'wo xiang shang qin hua da xue'\n",
    "string2 = 'wo xiang shang qing hua da xue' # <- \n",
    "string3 = 'wo xiang shang qing hua da xiu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7762036554131007e-16"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2_gram_model(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3136988054823888e-15"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2_gram_model(string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.648010077805309e-17"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2_gram_model(string3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.281580104131215e-18"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1_gram_prob_words('zhe ge hennnn qi guai'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4177790357182762e-24"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1_gram_prob_words('zhe ge gennnng hennnn qi guai'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0883637741169432e-12"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1_gram_prob_words('wo zai zuo ce shi'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1_gram_prob_words('wo zai zuo ce shi'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.126589655032671e-17"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1_gram_prob_words(string1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.980668075496288e-17"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1_gram_prob_words(string2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6954478376525142e-17"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1_gram_prob_words(string3.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 截止目前 我们能判断 句子的概率了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3： 修改、比、对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edist0(word):\n",
    "    return {word}\n",
    "\n",
    "def edist1(word):\n",
    "    'test'\n",
    "    't^est, te^st, '\n",
    "    split = get_splits(word)\n",
    "    deletes = get_deletes(split)\n",
    "    inserts = get_inserts(split)\n",
    "    replace = get_replaces(split)\n",
    "    transpose = get_transposes(split)\n",
    "    \n",
    "    return set(deletes + inserts + replace + transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edist1('wo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edist2(word):\n",
    "    return {e2 for e1 in edist1(word) for e2 in edist1(e1)}            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7154"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edist2('wo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    return {w for w in words if w in PINYIN_COUNT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known(edist2('wo')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(word):\n",
    "    \"Return a list of all possible (first, rest) pairs that comprise pinyin.\"\n",
    "    return [(word[:i], word[i:]) \n",
    "            for i in range(len(word)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'chang'),\n",
       " ('c', 'hang'),\n",
       " ('ch', 'ang'),\n",
       " ('cha', 'ng'),\n",
       " ('chan', 'g'),\n",
       " ('chang', '')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_split('chang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deletes(pairs):\n",
    "    return [a+b[1:] for (a, b) in pairs if b]\n",
    "\n",
    "def get_transposes(pairs):\n",
    "    return [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "\n",
    "def get_replaces(pairs):\n",
    "    return [a+c+b[1:]  for (a, b) in pairs for c in alphabet if b]\n",
    "\n",
    "def get_inserts(pairs):\n",
    "    return [a+c+b for (a, b) in pairs for c in alphabet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eng', 'mng', 'meg', 'men']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_deletes(get_split('meng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emng', 'mneg', 'megn']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_transposes(get_split('meng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_inserts(get_split('meng')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 我们能判断句子的概率了\n",
    "## Second 我们能修改生成拼音了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(word):\n",
    "    candidates = (known(edist0(word)) or \n",
    "                  known(edist1(word)) or \n",
    "                  known(edist2(word)) or \n",
    "                  [word])\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_correct(word):\n",
    "    \"Find the most possible pinyin based on edit distance.\"\n",
    "    \n",
    "    # Prefer edit distance 0, then 1, then 2; otherwise default to word itself.\n",
    "    \n",
    "    candidates = get_candidates(word)\n",
    "    \n",
    "    return max(candidates, key=PINYIN_COUNT.get) # return the most possible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xue'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct('xue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xue'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct('xuue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_correct_sequence(words):\n",
    "    return ' '.join(map(simple_correct, words.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhe shi ge ce shi'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct_sequence('zhe shi ge ce sho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wo xiang shang da xue'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct_sequence('wo xiang shang da xuue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shi'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct('shii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yu'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct('yeu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yi'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct('yyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xiang'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct('kiang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shi'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct('sho') # shi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhe shi ge ce shi'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct_sequence('zhe shi ge ce sho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wo xiang shang yu'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_correct_sequence('wo xiang ssang xyu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "+ 9k dataset \n",
    "+ 维基百科等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改的更复杂一些，能够处理上下文相关！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates_deep(word):\n",
    "    candidates = (known(edist0(word)) |\n",
    "                  known(edist1(word)) |\n",
    "                  known(edist2(word)) |\n",
    "                  set([word]))\n",
    "\n",
    "    return candidates    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_words_pair_2_gram(word_pair, topn=10):\n",
    "    head, tail = word_pair.split()\n",
    "\n",
    "    head_candidates = get_candidates_deep(head)\n",
    "    tail_candidates = get_candidates_deep(tail)\n",
    "    \n",
    "    return sorted([(h, t) for h in head_candidates for t in tail_candidates], \n",
    "               key=lambda x:_2_gram_model(' '.join(x)), reverse=True)[:topn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todo: 咱们可以把现在处理2个单词的词组，改成处理句子的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xiang', 'mu'),\n",
       " ('chang', 'yi'),\n",
       " ('wang', 'qiu'),\n",
       " ('lang', 'pu'),\n",
       " ('jiang', 'su'),\n",
       " ('jiang', 'yu'),\n",
       " ('bang', 'zhu'),\n",
       " ('shang', 'wu'),\n",
       " ('shan', 'xi'),\n",
       " ('sheng', 'wu')]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_words_pair_2_gram('ssang xyu') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('er', 'xian'),\n",
       " ('guo', 'ji'),\n",
       " ('she', 'ji'),\n",
       " ('fa', 'zhan'),\n",
       " ('guo', 'jia'),\n",
       " ('shi', 'jie'),\n",
       " ('shi', 'jian'),\n",
       " ('she', 'xin'),\n",
       " ('yi', 'yuan'),\n",
       " ('ri', 'dian'),\n",
       " ('yi', 'ji'),\n",
       " ('mu', 'qian'),\n",
       " ('shi', 'ji'),\n",
       " ('zi', 'ji'),\n",
       " ('shi', 'xian'),\n",
       " ('qiu', 'yuan'),\n",
       " ('an', 'quan'),\n",
       " ('de', 'ji'),\n",
       " ('ke', 'ji'),\n",
       " ('yi', 'jing')]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_words_pair_2_gram('hu jian', topn=20) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model\n",
    "## Edit Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token, Counter, RE, NLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
